{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949a21b8-f558-4ff3-9d85-4f9476093daa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This project prompts the user to give their thoughts on a movie they have seen. Then, it will provide an estimation of what that person would rate the movie out of 5, with 5 being the best and 1 being the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62cd010-518b-47d6-b1fe-46998f66aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessary packages and load the dataframe\n",
    "# CSV from https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset/\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "df = pd.read_csv('rotten_tomatoes_critic_reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4461fa57-f079-43a5-b0f4-d59a4c4bed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating necessary data from this project\n",
    "#Converting letter grades to numerical grades\n",
    "\n",
    "reviews = []\n",
    "ratings = []\n",
    "for review in df.itertuples(index=False):\n",
    "    if (type(review[5]) == str and type(review[7]) == str):\n",
    "        reviews.append(review[7])\n",
    "        if review[5] == 'A+':\n",
    "            ratings.append('5/5')\n",
    "        elif review[5] == 'A':\n",
    "            ratings.append('4.5/5')\n",
    "        elif review[5] == 'A-':\n",
    "            ratings.append('4.75/5')\n",
    "        elif review[5] == 'A  -':\n",
    "            ratings.append('4.75/5')\n",
    "        elif review[5] == 'B+':\n",
    "            ratings.append('4/5')\n",
    "        elif review[5] == 'B':\n",
    "            ratings.append('3.5/5')\n",
    "        elif review[5] == 'B-':\n",
    "            ratings.append('3.25/5')\n",
    "        elif review[5] == 'C+':\n",
    "            ratings.append('3/5')\n",
    "        elif review[5] == 'C':\n",
    "            ratings.append('2.5/5')\n",
    "        elif review[5] == 'C-':\n",
    "            ratings.append('2.25/5')\n",
    "        elif review[5] == 'C  -':\n",
    "            ratings.append('2.25/5')\n",
    "        elif review[5] == 'D+':\n",
    "            ratings.append('2/5')\n",
    "        elif review[5] == 'D':\n",
    "            ratings.append('1.5/5')\n",
    "        elif review[5] == 'D-':\n",
    "            ratings.append('1.25/5')\n",
    "        elif review[5] == 'F+':\n",
    "            ratings.append('1/5')\n",
    "        elif review[5] == 'F':\n",
    "            ratings.append('0.5/5')\n",
    "        elif review[5] == 'F-':\n",
    "            ratings.append('0.25/5')\n",
    "        else:\n",
    "            ratings.append(review[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade1be05-db6a-4bd7-853a-910506060560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting strings and fractions to floats for the LSTM\n",
    "#Taking in to account errors and some typos that were in the dataset\n",
    "\n",
    "ratings_as_float= []\n",
    "for i in ratings:\n",
    "    if '/' in i:\n",
    "        a , b = i.split(\"/\")\n",
    "        if float(b) == 0:\n",
    "            b = 100\n",
    "        to_float = float(a) / float(b)\n",
    "        ratings_as_float.append(to_float)\n",
    "    else:\n",
    "        if float(i) < 10:\n",
    "            ratings_as_float.append(float(i)/10)\n",
    "        elif float(i) <= 100:\n",
    "            ratings_as_float.append(float(i)/100)\n",
    "        else:\n",
    "            ratings_as_float.append(float(i)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada14cd7-7d27-4406-8c22-daddeb037d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load needed data into a dataframe\n",
    "Data = pd.DataFrame({'Review':reviews,'Rating':ratings_as_float})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48721ebe-7676-4428-9177-4c47c47da639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace non-letter characters with space\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s\\']', ' ', text)\n",
    "    text = re.sub(r' + ', ' ',text)\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8217a4f-f117-4b82-b99a-471f6330565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess\n",
    "Data['Review'] = Data['Review'].map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487169ff-ea1c-44e1-8ce5-cf0402370174",
   "metadata": {},
   "source": [
    "Fasttext Method\n",
    "\n",
    "Here, FastText is a scalable solution from Meta that, as far as I know, is the simplest way to do text classification.\n",
    "That being said, I want this project to give a percentage not classify categories. I am leaving this in case another user wants to look at it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c613ce-e4d2-4b32-9ed9-97ee9fb749e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess specifically for fasttext\n",
    "Data['Rating'] = \"__label__\" + (Data['Rating'].astype(str))\n",
    "Data[\"labeled_review\"] = Data['Rating'] + \" \" + Data['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77fa33b9-0f27-492b-8d41-3fbf19db0d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare test and training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(Data, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afbf6d5d-829c-4eaa-ae33-e5f4f3fb33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "train.to_csv(\"review.train\", columns=['labeled_review'], index=False, header=False)\n",
    "test.to_csv(\"review.test\", columns=['labeled_review'], index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce5511b5-6bf2-4e25-ad41-a6fd7367cfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37924, 0.25018457968568714, 0.25018457968568714)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run fasttext model\n",
    "import fasttext\n",
    "\n",
    "model = fasttext.train_supervised(\"review.train\")\n",
    "model.test(\"review.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ead923bc-ea02-4dba-8973-680f93305a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__0.8',), array([0.18067279]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict\n",
    "model.predict('The action scenes were good and the story and characters were amazing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd09ab-ba40-433f-8702-f5447fd954f5",
   "metadata": {},
   "source": [
    "LSTM Method\n",
    "\n",
    "As this is an NLP task, I chose to use an LSTM. Even though it is continuous and LSTMs generally work best with discrete classification, since my dataset is bounded between 0 and 1, combining an LSTM with dense layers with sigmoid activation functions works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0c1912f-8b66-48ef-98a5-ced7483f6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f46276fe-b309-4a19-9f52-7d52d3e78773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(Data, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdd27807-4aca-4376-beb9-74a8f2dc6086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sentences and prepare to tokenize data\n",
    "all_sentences = pd.concat([train, test], axis=0)\n",
    "tokenizer = Tokenizer(split=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78f0efdd-6792-417a-a0bd-166c1d67bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize all data\n",
    "tokenizer.fit_on_texts(all_sentences['Review'])\n",
    "sequences = tokenizer.texts_to_sequences(all_sentences['Review'])\n",
    "word_index = tokenizer.word_index\n",
    "data = sequence.pad_sequences(sequences, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47af9280-bf4c-4ec6-b750-9d2c850895f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare to vectorize data\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d3ded51-8731-4a3b-874e-8a5f8d5a2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building vocabulary to vectorize data\n",
    "fasttext_model=FastText(alpha=0.025,window=5,min_count=1,workers=4)\n",
    "fasttext_model.build_vocab(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f9b614d-867e-41b9-ac64-05fda48af30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizing data and saving model\n",
    "fasttext_model.train(sequences, total_examples=len(sequences), epochs=3)\n",
    "fasttext_model.save(\"review_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ec205ef-0f57-400b-b675-35b0434d696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131662\n"
     ]
    }
   ],
   "source": [
    "#Create embedding matrix based on vectorization\n",
    "vocab_size = len(word_index) + 1 \n",
    "print(vocab_size)\n",
    "embedding_matrix = np.random.random((vocab_size, 100))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = fasttext_model.wv[word]\n",
    "    except:\n",
    "        print(word, 'not found')\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i, :] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "512ca874-973d-4a04-bf02-80e0e6997e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan20\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'flatten_3' (of type Flatten) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Prepare model\n",
    "#Here I need an embedding layer since this is NLP and I have an embedding matrix for the vectorization\n",
    "#Masking layer since my dataset is masked\n",
    "#Bi-directional LSTM to learn context forwards and backwards\n",
    "#Flatten so that having a masking layer remains compatible with a dense layer\n",
    "model = keras.Sequential()\n",
    "model.add(Input(shape=(len(data[0]),), dtype='int32'))\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix], mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(units = 128, kernel_regularizer=l1(0.000001), return_sequences = True)))\n",
    "model.add(Dropout(rate = 0.1))\n",
    "model.add(Flatten())\n",
    "model.add(keras.layers.Masking(mask_value=0.))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bf623fd1-dbf1-4528-8a96-1e4fe59487c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,166,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15360</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15360</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,966,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │    \u001b[38;5;34m13,166,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m234,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15360\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking_1 (\u001b[38;5;33mMasking\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15360\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,966,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,367,033</span> (58.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,367,033\u001b[0m (58.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,367,033</span> (58.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,367,033\u001b[0m (58.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#View model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e4c2fdcc-aac4-4bbd-87ef-f9f034f7a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(531096, 60) (227613, 60)\n"
     ]
    }
   ],
   "source": [
    "#Prepare training and testing data\n",
    "\n",
    "train_data = data[:train.shape[0]]\n",
    "test_data = data[train.shape[0]:]\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2758c920-2efa-4cda-a9be-fbc923037241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further data preparation\n",
    "\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(train_data, train[\"Rating\"].values, test_size=0.3)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "95bff5f3-7063-46b1-a6fb-19cd8c13d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape consistency\n",
    "Y_train = np.asarray(Y_train).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "23043603-f08f-497f-a48c-fb9471c68d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan20\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'flatten_3' (of type Flatten) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2034/2034\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 240ms/step - loss: 0.1447 - mean_absolute_error: 0.1413 - val_loss: 0.1295 - val_mean_absolute_error: 0.1276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27970373590>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model - don't want to use accuracy since this is not a classification problem\n",
    "#I would run for more epochs but am limited in computing capabilities\n",
    "adam = Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_absolute_error',optimizer=adam,metrics=['mean_absolute_error'])\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=1, validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b301a225-faa8-4a01-812c-ec6a4e1eeb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1245/1245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 38ms/step - loss: 0.1237 - mean_absolute_error: 0.1218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12406165152788162, 0.12215328216552734]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking predictions on test dataset\n",
    "model.evaluate(X_test,Y_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "dc635d56-04a2-4d6d-8eae-2d737429c34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.55941737]], dtype=float32)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking predictions on user specified review\n",
    "a = np.array(tokenizer.texts_to_sequences(['I thought the movie was pretty bad, but I have definitely seen worse']))\n",
    "b = np.pad(a[0], (0,60-len(a[0])))\n",
    "model.predict(np.array([b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1f273c5a-5774-4df4-8d18-6728f5850357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/7113\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49:18\u001b[0m 416ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan20\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'flatten_3' (of type Flatten) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7113/7113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "test['Rating_Pred'] = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5d3394db-c8d3-4293-9634-56009eb2f1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35461692111482224"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.r2_score(test['Rating'].values, test['Rating_Pred'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
