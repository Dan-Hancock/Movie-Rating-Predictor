{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949a21b8-f558-4ff3-9d85-4f9476093daa",
   "metadata": {},
   "source": [
    "This project prompts the user to give their thoughts on a movie they have seen. Then, it will provide an estimation of what that person would rate the movie out of 5, with 5 being the best and 1 being the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549ebd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessary packages and load the dataframe\n",
    "# CSV from https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset/\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "df = pd.read_csv('rotten_tomatoes_critic_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4461fa57-f079-43a5-b0f4-d59a4c4bed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating necessary data from this project\n",
    "#Converting letter grades to numerical grades\n",
    "\n",
    "reviews = []\n",
    "ratings = []\n",
    "for review in df.itertuples(index=False):\n",
    "    if (type(review[5]) == str and type(review[7]) == str):\n",
    "        reviews.append(review[7])\n",
    "        if review[5] == 'A+':\n",
    "            ratings.append('5/5')\n",
    "        elif review[5] == 'A':\n",
    "            ratings.append('4.5/5')\n",
    "        elif review[5] == 'A-':\n",
    "            ratings.append('4.75/5')\n",
    "        elif review[5] == 'A  -':\n",
    "            ratings.append('4.75/5')\n",
    "        elif review[5] == 'B+':\n",
    "            ratings.append('4/5')\n",
    "        elif review[5] == 'B':\n",
    "            ratings.append('3.5/5')\n",
    "        elif review[5] == 'B-':\n",
    "            ratings.append('3.25/5')\n",
    "        elif review[5] == 'C+':\n",
    "            ratings.append('3/5')\n",
    "        elif review[5] == 'C':\n",
    "            ratings.append('2.5/5')\n",
    "        elif review[5] == 'C-':\n",
    "            ratings.append('2.25/5')\n",
    "        elif review[5] == 'C  -':\n",
    "            ratings.append('2.25/5')\n",
    "        elif review[5] == 'D+':\n",
    "            ratings.append('2/5')\n",
    "        elif review[5] == 'D':\n",
    "            ratings.append('1.5/5')\n",
    "        elif review[5] == 'D-':\n",
    "            ratings.append('1.25/5')\n",
    "        elif review[5] == 'F+':\n",
    "            ratings.append('1/5')\n",
    "        elif review[5] == 'F':\n",
    "            ratings.append('0.5/5')\n",
    "        elif review[5] == 'F-':\n",
    "            ratings.append('0.25/5')\n",
    "        else:\n",
    "            ratings.append(review[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1be05-db6a-4bd7-853a-910506060560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting strings and fractions to floats for the LSTM\n",
    "#Taking in to account errors and some typos that were in the dataset\n",
    "\n",
    "ratings_as_float= []\n",
    "for i in ratings:\n",
    "    if '/' in i:\n",
    "        a , b = i.split(\"/\")\n",
    "        if float(b) == 0:\n",
    "            b = 100\n",
    "        to_float = float(a) / float(b)\n",
    "        ratings_as_float.append(to_float)\n",
    "    else:\n",
    "        if float(i) < 10:\n",
    "            ratings_as_float.append(float(i)/10)\n",
    "        elif float(i) <= 100:\n",
    "            ratings_as_float.append(float(i)/100)\n",
    "        else:\n",
    "            ratings_as_float.append(float(i)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada14cd7-7d27-4406-8c22-daddeb037d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load needed data into a dataframe\n",
    "Data = pd.DataFrame({'Review':reviews,'Rating':ratings_as_float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48721ebe-7676-4428-9177-4c47c47da639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace non-letter characters with space\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s\\']', ' ', text)\n",
    "    text = re.sub(r' + ', ' ',text)\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8217a4f-f117-4b82-b99a-471f6330565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess\n",
    "Data['Review'] = Data['Review'].map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487169ff-ea1c-44e1-8ce5-cf0402370174",
   "metadata": {},
   "source": [
    "Fasttext Method\n",
    "\n",
    "Note: This method only works for discrete classification\n",
    "Here, we are trying to make predictions on a continuous set from 0 to 1, so rather than fasttext, other methods are preferred and are seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c613ce-e4d2-4b32-9ed9-97ee9fb749e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess specifically for fasttext\n",
    "Data['Rating'] = \"__label__\" + (Data['Rating'].astype(str))\n",
    "Data[\"labeled_review\"] = Data['Rating'] + \" \" + Data['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa33b9-0f27-492b-8d41-3fbf19db0d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare test and training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(Data, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf6d5d-829c-4eaa-ae33-e5f4f3fb33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "train.to_csv(\"review.train\", columns=['labeled_review'], index=False, header=False)\n",
    "test.to_csv(\"review.test\", columns=['labeled_review'], index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5511b5-6bf2-4e25-ad41-a6fd7367cfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37924, 0.25018457968568714, 0.25018457968568714)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run fasttext model\n",
    "import fasttext\n",
    "\n",
    "model = fasttext.train_supervised(\"review.train\")\n",
    "model.test(\"review.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead923bc-ea02-4dba-8973-680f93305a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__0.8',), array([0.18067279]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict\n",
    "model.predict('The action scenes were good and the story and characters were amazing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd09ab-ba40-433f-8702-f5447fd954f5",
   "metadata": {},
   "source": [
    "LSTM Method\n",
    "\n",
    "As this is an NLP task, I choose to use an LSTM. Even though it is continuous and LSTMs generally work best with discrete classification, since my dataset is bounded between 0 and 1, using a sigmoid activation function can make it work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1912f-8b66-48ef-98a5-ced7483f6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46276fe-b309-4a19-9f52-7d52d3e78773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(Data, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd27807-4aca-4376-beb9-74a8f2dc6086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sentences and prepare to tokenize data\n",
    "all_sentences = pd.concat([train, test], axis=0)\n",
    "tokenizer = Tokenizer(split=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0efdd-6792-417a-a0bd-166c1d67bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize all data extracting important features\n",
    "\n",
    "tokenizer.fit_on_texts(all_sentences['Review'])\n",
    "sequences = tokenizer.texts_to_sequences(all_sentences['Review'])\n",
    "word_index = tokenizer.word_index\n",
    "data = sequence.pad_sequences(sequences, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47af9280-bf4c-4ec6-b750-9d2c850895f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize data\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ded51-8731-4a3b-874e-8a5f8d5a2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building vocab to vectorize data\n",
    "fasttext_model=FastText(alpha=0.025,window=5,min_count=1,workers=4)\n",
    "fasttext_model.build_vocab(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b614d-867e-41b9-ac64-05fda48af30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizing data\n",
    "fasttext_model.train(sequences, total_examples=len(sequences), epochs=3)\n",
    "fasttext_model.save(\"review_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec205ef-0f57-400b-b675-35b0434d696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131662\n"
     ]
    }
   ],
   "source": [
    "#Create embedding matrix based on vectorization\n",
    "vocab_size = len(word_index) + 1 \n",
    "print(vocab_size)\n",
    "embedding_matrix = np.random.random((vocab_size, 100))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = fasttext_model.wv[word]\n",
    "    except:\n",
    "        print(word, 'not found')\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i, :] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea7bff",
   "metadata": {},
   "source": [
    "Here I use an embedded layer for the vectorization\n",
    "The bidirectional LSTM layer is used so that the model gains context both forwards and backwards in the text sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ca874-973d-4a04-bf02-80e0e6997e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model\n",
    "model = keras.Sequential()\n",
    "model.add(Input(shape=(len(data[0]),), dtype='int32'))\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix]))\n",
    "model.add(Bidirectional(LSTM(units = 128, kernel_regularizer=l1(0.000001), return_sequences = True)))\n",
    "model.add(Dropout(rate = 0.1))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf623fd1-dbf1-4528-8a96-1e4fe59487c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 60)]              0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 60, 100)           13166200  \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 60, 256)           234496    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 60, 256)           0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 60, 128)           32896     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 60, 1)             129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13433721 (51.25 MB)\n",
      "Trainable params: 13433721 (51.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Viewing model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2fdcc-aac4-4bbd-87ef-f9f034f7a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(531096, 60) (227613, 60)\n"
     ]
    }
   ],
   "source": [
    "#Checking shape and making train and test for the model\n",
    "train_data = data[:train.shape[0]]\n",
    "test_data = data[train.shape[0]:]\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758c920-2efa-4cda-a9be-fbc923037241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data as necessary\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(train_data, train[\"Rating\"].values, test_size=0.3)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bff5f3-7063-46b1-a6fb-19cd8c13d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restructuring dependent variable as necessary\n",
    "Y_train = np.asarray(Y_train).astype('float32').reshape((-1,1))\n",
    "Y_test = np.asarray(Y_test).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efafcf9",
   "metadata": {},
   "source": [
    "Here, since it is a continuous problem, we want to use either mean absolute or mean squared error\n",
    "I choose mean squared error because I want the training to punish outliers since some reviewers give unfair/unreasonable reviews\n",
    "It should be noted that since this is a continuous problem, the standard accuracy metric isn't useful. Instead, later I'll use the R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23043603-f08f-497f-a48c-fb9471c68d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034/2034 [==============================] - 842s 412ms/step - loss: 0.1339 - accuracy: 0.0556 - val_loss: 0.2003 - val_accuracy: 0.0461\n"
     ]
    }
   ],
   "source": [
    "#Setting optimizer and fitting the model\n",
    "adam = Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_sqared_error',optimizer=adam,metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=128, epochs=5, validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f273c5a-5774-4df4-8d18-6728f5850357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking predictions on test dataset\n",
    "model.evaluate(X_test,Y_test,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c62cb-32c3-432b-bf38-299368724104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking predictions on user specified review\n",
    "a = np.array(tokenizer.texts_to_sequences(['quite possibly the worst movie ever made']))\n",
    "model.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(test_data)\n",
    "results_mean = []\n",
    "i = 0\n",
    "while i < len(test['Rating'].values):\n",
    "    testings.append(results[i][0])\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4958ccd",
   "metadata": {},
   "source": [
    "Here, the R^2 value in combination with the loss from before can be used to determine the effectiveness of the model\n",
    "\n",
    "It is important that an R^2 approaching 1 may not be ideal as it could indicate overfitting.\n",
    "Additionally, an R^2 of 0 indicates that the model always predicts the mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8349d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.r2_score(test['Rating'].values, testings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d5aea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f2348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86599d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
